{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-FUJZt6DW9v"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "def get_column(data, index):\n",
        "    result = [row[index] for row in data]\n",
        "    return result\n",
        "\n",
        "def prepare_data(file_name_dataset):\n",
        "    data = np.genfromtxt(file_name_dataset, delimiter=',', skip_header=1).tolist()\n",
        "    N = len(data)\n",
        "\n",
        "    # get tv (index=0)\n",
        "    tv_data = get_column(data, 0)\n",
        "\n",
        "    # get radio (index=1)\n",
        "    radio_data = get_column(data, 1)\n",
        "\n",
        "    # get newspaper (index=2)\n",
        "    newspaper_data = get_column(data, 2)\n",
        "\n",
        "    # get sales (index=3)\n",
        "    sales_data = get_column(data, 3)\n",
        "\n",
        "    # building X input and y output for training\n",
        "    X = [tv_data, radio_data, newspaper_data]\n",
        "    y = sales_data\n",
        "    return X, y\n",
        "\n",
        "def initialize_params():\n",
        "    w1, w2, w3, b = (0.016992259082509283, 0.0070783670518262355,\n",
        "                     -0.002307860847821344, 0)\n",
        "    return w1, w2, w3, b\n",
        "\n",
        "def predict(x1, x2, x3, w1, w2, w3, b):\n",
        "    return w1 * x1 + w2 * x2 + w3 * x3 + b\n",
        "\n",
        "def compute_loss_mse(y_hat, y):\n",
        "    return (y_hat - y) ** 2\n",
        "\n",
        "def compute_loss_mae(y_hat, y):\n",
        "    return abs(y_hat - y)\n",
        "\n",
        "def compute_gradient_wi(xi, y, y_hat):\n",
        "    return 2 * xi * (y_hat - y)\n",
        "\n",
        "def compute_gradient_b(y, y_hat):\n",
        "    return 2 * (y_hat - y)\n",
        "\n",
        "def update_weight_wi(wi, dl_dwi, lr):\n",
        "    return wi - lr * dl_dwi\n",
        "\n",
        "def update_weight_b(b, dl_db, lr):\n",
        "    return b - lr * dl_db\n",
        "\n",
        "def implement_linear_regression(X_data, y_data, epoch_max=50, lr=1e-5):\n",
        "    losses = []\n",
        "\n",
        "    w1, w2, w3, b = initialize_params()\n",
        "\n",
        "    N = len(y_data)\n",
        "    for epoch in range(epoch_max):\n",
        "        for i in range(N):\n",
        "            # get a sample\n",
        "            x1 = X_data[0][i]\n",
        "            x2 = X_data[1][i]\n",
        "            x3 = X_data[2][i]\n",
        "\n",
        "            y = y_data[i]\n",
        "\n",
        "            # compute output\n",
        "            y_hat = predict(x1, x2, x3, w1, w2, w3, b)\n",
        "\n",
        "            # compute loss\n",
        "            loss = compute_loss_mse(y, y_hat)\n",
        "\n",
        "            # compute gradient w1, w2, w3, b\n",
        "            dl_dw1 = compute_gradient_wi(x1, y, y_hat)\n",
        "            dl_dw2 = compute_gradient_wi(x2, y, y_hat)\n",
        "            dl_dw3 = compute_gradient_wi(x3, y, y_hat)\n",
        "            dl_db = compute_gradient_b(y, y_hat)\n",
        "\n",
        "            # update parameters\n",
        "            w1 = update_weight_wi(w1, dl_dw1, lr)\n",
        "            w2 = update_weight_wi(w2, dl_dw2, lr)\n",
        "            w3 = update_weight_wi(w3, dl_dw3, lr)\n",
        "            b = update_weight_b(b, dl_db, lr)\n",
        "\n",
        "            # logging\n",
        "            losses.append(loss)\n",
        "    return (w1, w2, w3, b, losses)\n",
        "\n",
        "def implement_linear_regression_nsamples(X_data, y_data, epoch_max=50, lr=1e-5):\n",
        "    losses = []\n",
        "\n",
        "    w1, w2, w3, b = initialize_params()\n",
        "    N = len(y_data)\n",
        "\n",
        "    for epoch in range(epoch_max):\n",
        "        loss_total = 0.0\n",
        "        dw1_total = 0.0\n",
        "        dw2_total = 0.0\n",
        "        dw3_total = 0.0\n",
        "        db_total = 0.0\n",
        "\n",
        "        for i in range(N):\n",
        "            # get a sample\n",
        "            x1 = X_data[0][i]\n",
        "            x2 = X_data[1][i]\n",
        "            x3 = X_data[2][i]\n",
        "\n",
        "            y = y_data[i]\n",
        "\n",
        "            # compute output\n",
        "            y_hat = predict(x1, x2, x3, w1, w2, w3, b)\n",
        "\n",
        "            # compute loss\n",
        "            loss = compute_loss_mse(y, y_hat)\n",
        "\n",
        "            # accumulate loss\n",
        "            loss_total += loss\n",
        "\n",
        "            # compute gradient w1, w2, w3, b\n",
        "            dl_dw1 = compute_gradient_wi(x1, y, y_hat)\n",
        "            dl_dw2 = compute_gradient_wi(x2, y, y_hat)\n",
        "            dl_dw3 = compute_gradient_wi(x3, y, y_hat)\n",
        "            dl_db = compute_gradient_b(y, y_hat)\n",
        "\n",
        "            # accumulate gradient w1, w2, w3, b\n",
        "            dw1_total += dl_dw1\n",
        "            dw2_total += dl_dw2\n",
        "            dw3_total += dl_dw3\n",
        "            db_total += dl_db\n",
        "\n",
        "        # (after processing N samples) - update parameters\n",
        "        w1 = update_weight_wi(w1, dw1_total / N, lr)\n",
        "        w2 = update_weight_wi(w2, dw2_total / N, lr)\n",
        "        w3 = update_weight_wi(w3, dw3_total / N, lr)\n",
        "        b = update_weight_b(b, db_total / N, lr)\n",
        "\n",
        "        # logging\n",
        "        losses.append(loss_total / N)\n",
        "    return (w1, w2, w3, b, losses)\n",
        "\n",
        "# For the last part of the exercise\n",
        "def prepare_data_features(file_name_dataset):\n",
        "    data = np.genfromtxt(file_name_dataset, delimiter=',', skip_header=1).tolist()\n",
        "\n",
        "    # get tv (index=0)\n",
        "    tv_data = get_column(data, 0)\n",
        "\n",
        "    # get radio (index=1)\n",
        "    radio_data = get_column(data, 1)\n",
        "\n",
        "    # get newspaper (index=2)\n",
        "    newspaper_data = get_column(data, 2)\n",
        "\n",
        "    # get sales (index=3)\n",
        "    sales_data = get_column(data, 3)\n",
        "\n",
        "    # building X input and y output for training\n",
        "    # Create list of features for input\n",
        "    X = [[1, x1, x2, x3] for x1, x2, x3 in zip(tv_data, radio_data, newspaper_data)]\n",
        "    y = sales_data\n",
        "    return X, y\n",
        "\n",
        "def initialize_params_features():\n",
        "    return [0, -0.01268850433497871, 0.004752496982185252, 0.0073796171538643845]\n",
        "\n",
        "def predict_features(X_features, weights):\n",
        "    return sum(x * w for x, w in zip(X_features, weights))\n",
        "\n",
        "def compute_gradient_w_features(X_features, y, y_hat):\n",
        "    return [2 * x * (y_hat - y) for x in X_features]\n",
        "\n",
        "def update_weight_features(weights, dl_dweights, lr):\n",
        "    return [w - lr * dw for w, dw in zip(weights, dl_dweights)]\n",
        "\n",
        "def implement_linear_regression_features(X_feature, y_output, epoch_max=50, lr=1e-5):\n",
        "    losses = []\n",
        "    weights = initialize_params_features()\n",
        "    N = len(y_output)\n",
        "    for epoch in range(epoch_max):\n",
        "        print(\"epoch\", epoch)\n",
        "        for i in range(N):\n",
        "            # get a sample - row i\n",
        "            features_i = X_feature[i]\n",
        "            y = y_output[i]\n",
        "\n",
        "            # compute output\n",
        "            y_hat = predict_features(features_i, weights)\n",
        "\n",
        "            # compute loss\n",
        "            loss = compute_loss_mse(y, y_hat)\n",
        "\n",
        "            # compute gradient w1, w2, w3, b\n",
        "            dl_dweights = compute_gradient_w_features(features_i, y, y_hat)\n",
        "\n",
        "            # update parameters\n",
        "            weights = update_weight_features(weights, dl_dweights, lr)\n",
        "\n",
        "            # logging\n",
        "            losses.append(loss)\n",
        "    return weights, losses\n",
        "\n",
        "# Main execution\n",
        "X, y = prepare_data('advertising.csv')\n",
        "W, L = implement_linear_regression(X, y)\n",
        "plt.plot(L[0:100])\n",
        "plt.xlabel(\"# iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "# For the last part\n",
        "X_features, y_features = prepare_data_features('advertising.csv')\n",
        "W_features, L_features = implement_linear_regression_features(X_features, y_features)\n",
        "plt.plot(L_features[0:100])\n",
        "plt.xlabel(\"# iteration\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.show()\n",
        "\n",
        "# Print loss value at iteration 9999\n",
        "print(L_features[9999])"
      ]
    }
  ]
}