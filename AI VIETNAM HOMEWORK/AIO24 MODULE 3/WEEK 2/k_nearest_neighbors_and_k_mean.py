# -*- coding: utf-8 -*-
"""K-Nearest Neighbors and K-Mean

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1aX0JuIBTVL5aCZ99k5kuK9uc_i9scmOL
"""

import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier

iris_X, iris_y = datasets.load_iris(return_X_y=True)

# Use iris_X instead of iris_
X_train, X_test, y_train, y_test = train_test_split(iris_X, # Changed this line
                                                    iris_y,
                                                    test_size = 0.2,
                                                    random_state = 42)
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Build KNN classifier
classifier = KNeighborsClassifier(n_neighbors=8)
classifier.fit(X_train, y_train)

# Also, knn_classifier is not defined, it should be classifier
y_pred = classifier.predict(X_test) # Changed this line

accuracy = classifier.score(X_test, y_test)

import numpy as np
from sklearn import datasets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsRegressor

#Paragraph A:
# Load the diabetes dataset
diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)

#Paragraph D:
# Split train:test = 8:2
X_train, X_test, y_train, y_test = train_test_split(
diabetes_X,
diabetes_y,
test_size=0.2,
random_state=42
)

#Paragraph B:
# Scale the features using StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Paragraph C:
# Build KNN model
knn_regressor = KNeighborsRegressor(n_neighbors=5)
knn_regressor.fit(X_train, y_train)

# Import library
!pip install -q datasets
import numpy as np
from datasets import load_dataset
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import StandardScaler
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.metrics import accuracy_score # Import accuracy_score

# Load IMDB dataset
imdb = load_dataset("imdb")
imdb_train, imdb_test = imdb['train'], imdb['test']

# Convert text to vector using BoW
vectorizer = CountVectorizer(max_features=1000)
X_train = vectorizer.fit_transform(imdb_train['text']).toarray()

# Access the 'text' column using square brackets instead of parentheses
X_test = vectorizer.transform(imdb_test['text']).toarray()
y_train = np.array(imdb_train['label'])
y_test = np.array(imdb_test['label'])

# Scale the features using StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Build KNN Classifier
# Use n_neighbors instead of neighbors
knn_classifier = KNeighborsClassifier(n_neighbors=1, algorithm='ball_tree')
knn_classifier.fit(X_train, y_train)

# predict test set and evaluate
y_pred = knn_classifier.predict(X_test)
print(accuracy_score(y_test, y_pred)) # Print the accuracy score

"""K MEANS"""

from sklearn.datasets import load_iris
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

iris_dataset = load_iris()
data = iris_dataset.data
data = iris_dataset.data[:, :2]

plt.scatter(data[:, 0], data[:, 1], label='True Position', c = 'gray')
plt.title('Initial Dataset')
plt.xlabel('Sepal Length')
plt.ylabel('Sepal Width')
plt.legend()
plt.show

class KMeans:
  def __init__(self, n_clusters=8, max_iter=300):
    self.k = k
    self.max_iter = max_iter
    self.centroids = None
    self.clusters = None

  def initialize_centroids(self, data):
    np.random.seed (42)
    self.centroids = data[np.random.choice(data.shape[0], self.k, replace=False)]

  def assign_clusters(self, data):
    distances = np.sqrt(((data - self.centroids[:, np.newaxis])**2).sum(axis=2))
    self.clusters = np.argmin(distances, axis=0)

  def update_centroids(self, data):
      return np.array([data[self.clusters == i].mean(axis=0) for i in range(self.k)])

  def fit(self, data):
      self.initialize_centroids(data)

      for i in range(self.max_iters):
          self.clusters = self.assign_clusters(data)
          self.plot_clusters(data, i)
          new_centroids = self.update_centroids(data)
          if np.all(self.centroids == new_centroids):
              break
          self.centroids = new_centroids
      self.plot_final_clusters(data)

  def plot_clusters(self, data, iteration):
      plt.scatter(data[:, 0], data[:, 1], c=self.clusters, cmap='viridis', marker='o',
      alpha=0.6)
      plt.scatter(self.centroids[:, 0], self.centroids[:, 1], s=300, c='red', marker='x')
      plt.title(f"Iteration {iteration + 1}")
      plt.xlabel('Sepal length')
      plt.ylabel('Sepal width')
      plt.show()


def plot_final_clusters(self, data):
    plt.scatter(data[:, 0], data[:, 1], c=self.clusters, cmap='viridis', marker='o',
    alpha=0.6)
    plt.scatter(self.centroids[:, 0], self.centroids[:, 1], s=300, c='red', marker='x')
    plt.title("Final Clusters and Centroids")
    plt.xlabel('Sepal length')
    plt.ylabel('Sepal width')
    plt.show()

kmeans = KMeans(k = 2)
kmeans.fit(data)
kmeans = KMeans(k = 3)
kmeans.fit(data)
kmeans = KMeans(k = 4)
kmeans.fit(data)